{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "at_U_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acrcRmmwrwvX"
      },
      "source": [
        "# Import data and packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrozW7WXkFN1",
        "outputId": "74601eac-e733-42d5-9c92-7112fd6149cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/helpers.py\" .\n",
        "!cp -av \"/content/drive/MyDrive/Colab Notebooks/at_dataset\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7cDqXqaGk_A"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "import cv2 as cv\n",
        "from helpers import *\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV81YSi0Gk_B"
      },
      "source": [
        "#Accuracy \n",
        "def accuracy(pred, test_labels):\n",
        "    '''\n",
        "    pred: torch.tensor (result of U-net) of size [num_batches=1, 2, dim_image1, dim_image2]\n",
        "    test_labels: torch.tensor (Real labels for the image) \n",
        "    '''\n",
        "    '''\n",
        "    Calculate the percentage of correct pixels labeled\n",
        "    '''\n",
        "    label_pred=torch.argmax(pred,dim=1)\n",
        "    error = (torch.abs(label_pred-test_labels)).mean()\n",
        "    return 1-error "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH-9vSWJuX_-"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling and conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "        # self.up_conv = nn.Sequential(\n",
        "        #   nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "        #   nn.Conv2d(in_channels, out_channels, kernel_size=2)\n",
        "        # )\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=2, padding=1, dilation=2)\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # up-conv input\n",
        "        x1 = self.up(x1)\n",
        "        x1 = self.conv(x1)\n",
        "\n",
        "        # crop and contatinate\n",
        "        diffY = int((x2.size()[2] - x1.size()[2]) // 2)\n",
        "        diffX = int((x2.size()[3] - x1.size()[3]) // 2)\n",
        "        x2 = x2[:,:,diffY:-diffY, diffX:-diffX]\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1aMnQ24jpGz"
      },
      "source": [
        "class U_net(nn.Module):\n",
        "    def __init__(self, n_channels=1, n_classes=2, bilinear=True):\n",
        "        super(U_net, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.up1 = Up(1024, 512, bilinear)\n",
        "        self.up2 = Up(512, 256, bilinear)\n",
        "        self.up3 = Up(256, 128, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5E9lylozMEC"
      },
      "source": [
        "#Training (adapting function from lab10)\n",
        "def train(model, criterion, pathX, pathY, optimizer, num_epochs, data_size, split, device):\n",
        "  \"\"\"\n",
        "  @param model: torch.nn.Module\n",
        "  @param criterion: torch.nn.modules.loss._Loss\n",
        "  @param image_input: numpy.ndarray\n",
        "  @param labeled_images: numpy.ndarray\n",
        "  @param optimizer: torch.optim.Optimizer\n",
        "  @param num_epochs: int\n",
        "  \"\"\"\n",
        "  in_size, out_size = 572, 388\n",
        "  # split dataset\n",
        "  imgs_names = np.array(sorted(glob.glob(pathX)),dtype=object)\n",
        "  labels_names = np.array(sorted(glob.glob(pathY)),dtype=object)\n",
        "  idx = np.random.choice(len(imgs_names),data_size)\n",
        "  idx_train = idx[:int(split*data_size)]\n",
        "  idx_test = idx[int(split*data_size):]\n",
        "  img_names_train = imgs_names[idx_train]\n",
        "  img_names_test = imgs_names[idx_test]\n",
        "  labels_names_train = labels_names[idx_train]\n",
        "  labels_names_test = labels_names[idx_test]\n",
        "\n",
        "  print(\"Starting training\")\n",
        "  #Cycle for epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # Train an epoch\n",
        "    model.train()\n",
        "    for i,img_path in enumerate(img_names_train):\n",
        "      print(f'epoch: {epoch+1}/{num_epochs}, img: {i+1}/{len(img_names_train)}')\n",
        "      # load individual image and label and segment them\n",
        "      img = [cv.imread(img_path, cv.IMREAD_UNCHANGED)/(2**16-1)]\n",
        "      lbl = [cv.imread(labels_names_train[i], cv.IMREAD_UNCHANGED)]\n",
        "      X, y = segment_dataset(img, lbl, in_size, out_size, extend = True, augment=False)\n",
        "      Y = np.repeat(y[:, np.newaxis, :, :], 2, axis=1).astype(np.uint8)\n",
        "      Y[:,0,:,:] ^= True\n",
        "\n",
        "      for j in range(X.shape[0]):\n",
        "        # print(f'epoch: {epoch+1}/{num_epochs}, img: {i+1}/{len(img_names_train)}, segment: {j+1}/{X.shape[0]}')\n",
        "        # convert numpy values to tensor form and load to GPU\n",
        "        tensor_X = torch.Tensor(X[j]).view(1,1,in_size,in_size)\n",
        "        tensor_Y = torch.Tensor(Y[j]).view(1,2,out_size,out_size)\n",
        "        tensor_X, tensor_Y = tensor_X.to(device), tensor_Y.to(device)\n",
        "\n",
        "        # Evaluate the network (forward pass)\n",
        "        prediction = model(tensor_X)\n",
        "        loss = criterion(prediction,tensor_Y)\n",
        "        \n",
        "        # Compute the gradient\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters of the model with a gradient step\n",
        "        optimizer.step()\n",
        "\n",
        "  model.eval()\n",
        "  # accuracies_test = []\n",
        "  for i,img_path in enumerate(img_names_test):\n",
        "    # load individual image and label and segment them\n",
        "    img = [cv.imread(img_path, cv.IMREAD_UNCHANGED)/(2**16-1)]\n",
        "    lbl = [cv.imread(labels_names_test[i], cv.IMREAD_UNCHANGED)]\n",
        "    X, y = segment_dataset(img, lbl, in_size, out_size, extend = True, augment=False)\n",
        "\n",
        "    for j in range(X.shape[0]):\n",
        "      # convert numpy values to tensor form and load to GPU\n",
        "      tensor_X = torch.Tensor(X[j]).view(1,1,in_size,in_size)\n",
        "      tensor_y = torch.Tensor(y[j].astype(np.uint8)).view(1,1,out_size,out_size)\n",
        "      tensor_X, tensor_y= tensor_X.to(device), tensor_y.to(device)\n",
        "\n",
        "      # Evaluate the network (forward pass)\n",
        "      prediction = model(tensor_X)\n",
        "      # accuracies_test.append(accuracy(prediction, tensor_y))\n",
        "      accuracies_test = accuracy(prediction, tensor_y)\n",
        "      print(\"Test accuracy: {:.5f}\".format(accuracies_test.item()))\n",
        "\n",
        "      pred = prediction.to(\"cpu\")\n",
        "      pred = torch.argmax(pred,dim=1)\n",
        "      # plot\n",
        "      plt.figure(figsize=(10,4))\n",
        "      plt.subplot(121)\n",
        "      plt.imshow(y[j])\n",
        "      plt.axis('off')\n",
        "      plt.title('Original')\n",
        "      plt.subplot(122)\n",
        "      plt.imshow(pred.view(388,388))\n",
        "      plt.axis('off')\n",
        "      plt.title('Prediction')\n",
        "      plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsZfLMYfNBMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f69940e-41cb-40c6-8a8c-eefd9ee3a83c"
      },
      "source": [
        "num_epochs=15\n",
        "learning_rate=0.001\n",
        "data_size = 100\n",
        "split = 0.65\n",
        "\n",
        "pathX = '/content/at_dataset/images/*.tif'\n",
        "pathY = '/content/at_dataset/labels/*.tiff'\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"Things will go much quicker if you enable a GPU in Colab under 'Runtime / Change Runtime Type'\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model=U_net().to(device)\n",
        "\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.99)\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "\n",
        "train(model, criterion, pathX, pathY, optimizer, num_epochs, data_size, split, device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFS7sxGn3y7b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}