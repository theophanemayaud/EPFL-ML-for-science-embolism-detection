{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "at_U_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acrcRmmwrwvX"
      },
      "source": [
        "# Import data and packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrozW7WXkFN1",
        "outputId": "47fdf303-68d0-40e0-a1af-8ff9ddaa728f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!cp \"/content/drive/MyDrive/Colab Notebooks/helpers.py\" .\n",
        "!cp -av \"/content/drive/MyDrive/Colab Notebooks/at_dataset\" ."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "'/content/drive/MyDrive/Colab Notebooks/at_dataset' -> './at_dataset'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7cDqXqaGk_A"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "import cv2 as cv\n",
        "from helpers import *\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xt_dQyy7jpGy",
        "outputId": "1e6fdb14-e648-415d-a865-91b85dbb77de"
      },
      "source": [
        "imgs_names = np.array(sorted(glob.glob('/content/at_dataset/images/*.tif')),dtype=object)\n",
        "labels_names = np.array(sorted(glob.glob('/content/at_dataset/labels/*.tiff')),dtype=object)\n",
        "idx = np.random.choice(len(imgs_names),5)\n",
        "imgs = [cv.imread(name, cv.IMREAD_UNCHANGED)/(2**16-1) for name in imgs_names[idx]]\n",
        "labels = [cv.imread(name, cv.IMREAD_UNCHANGED) for name in labels_names[idx]]\n",
        "print(f'num data: {len(imgs)}, num labels: {len(labels)}')\n",
        "X, y = segment_dataset(imgs, labels, augment=False)\n",
        "# segment_dataset(imgs, labels, augment=True,store=True)\n",
        "print(f'X.shape: {X.shape}, y.shape: {y.shape}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num data: 5, num labels: 5\n",
            "X.shape: (57, 572, 572), y.shape: (57, 388, 388)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ci67kAYgxdyw",
        "outputId": "927b9382-758e-42f9-e316-124eb03b6224"
      },
      "source": [
        "# set up output style labels\n",
        "Y = np.repeat(y[:, np.newaxis, :, :], 2, axis=1).astype(np.uint8)\n",
        "Y[:,0,:,:] ^= True\n",
        "print(f'X.shape: {X.shape}, Y.shape: {Y.shape}')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X.shape: (57, 572, 572), Y.shape: (57, 2, 388, 388)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV81YSi0Gk_B"
      },
      "source": [
        "#Accuracy \n",
        "def accuracy(pred, test_labels):\n",
        "    '''\n",
        "    pred: torch.tensor (result of U-net) of size [num_batches=1, 2, dim_image1, dim_image2]\n",
        "    test_labels: torch.tensor (Real labels for the image) \n",
        "    '''\n",
        "    '''\n",
        "    Calculate the percentage of correct pixels labeled\n",
        "    '''\n",
        "    test_labels=test_labels.view(1,test_labels)\n",
        "    label_pred=torch.argmax(pred,dim=1)\n",
        "    acc= (torch.abs(label_pred-test_labels)).mean()\n",
        "    return 1-acc "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH-9vSWJuX_-"
      },
      "source": [
        "# class DoubleConv(nn.Module):\n",
        "#     \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "#     def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "#         super().__init__()\n",
        "#         if not mid_channels:\n",
        "#             mid_channels = out_channels\n",
        "#         self.double_conv = nn.Sequential(\n",
        "#             nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "#             nn.BatchNorm2d(mid_channels),\n",
        "#             nn.ReLU(inplace=True),\n",
        "#             nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "#             nn.BatchNorm2d(out_channels),\n",
        "#             nn.ReLU(inplace=True)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.double_conv(x)\n",
        "\n",
        "\n",
        "# class Down(nn.Module):\n",
        "#     \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super().__init__()\n",
        "#         self.maxpool_conv = nn.Sequential(\n",
        "#             nn.MaxPool2d(2),\n",
        "#             DoubleConv(in_channels, out_channels)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "# class Up(nn.Module):\n",
        "#     \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "#     def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "#         super().__init__()\n",
        "\n",
        "#         # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "#         if bilinear:\n",
        "#             self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "#             self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "#         else:\n",
        "#             self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
        "#             self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "#     def forward(self, x1, x2):\n",
        "#         x1 = self.up(x1)\n",
        "#         # input is CHW\n",
        "#         diffY = x2.size()[2] - x1.size()[2]\n",
        "#         diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "#         x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "#                         diffY // 2, diffY - diffY // 2])\n",
        "#         # if you have padding issues, see\n",
        "#         # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "#         # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "#         x = torch.cat([x2, x1], dim=1)\n",
        "#         return self.conv(x)\n",
        "\n",
        "\n",
        "# class OutConv(nn.Module):\n",
        "#     def __init__(self, in_channels, out_channels):\n",
        "#         super(OutConv, self).__init__()\n",
        "#         self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         return self.conv(x)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1aMnQ24jpGz"
      },
      "source": [
        "# class U_net(nn.Module):\n",
        "#     def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "#         super(U_net, self).__init__()\n",
        "#         self.n_channels = n_channels\n",
        "#         self.n_classes = n_classes\n",
        "#         self.bilinear = bilinear\n",
        "\n",
        "#         self.inc = DoubleConv(n_channels, 64)\n",
        "#         self.down1 = Down(64, 128)\n",
        "#         self.down2 = Down(128, 256)\n",
        "#         self.down3 = Down(256, 512)\n",
        "#         factor = 2 if bilinear else 1\n",
        "#         self.down4 = Down(512, 1024 // factor)\n",
        "#         self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "#         self.up2 = Up(512, 256 // factor, bilinear)\n",
        "#         self.up3 = Up(256, 128 // factor, bilinear)\n",
        "#         self.up4 = Up(128, 64, bilinear)\n",
        "#         self.outc = OutConv(64, n_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x1 = self.inc(x)\n",
        "#         x2 = self.down1(x1)\n",
        "#         x3 = self.down2(x2)\n",
        "#         x4 = self.down3(x3)\n",
        "#         x5 = self.down4(x4)\n",
        "#         x = self.up1(x5, x4)\n",
        "#         x = self.up2(x, x3)\n",
        "#         x = self.up3(x, x2)\n",
        "#         x = self.up4(x, x1)\n",
        "#         logits = self.outc(x)\n",
        "#         return logits\n",
        "class U_net(nn.Module):\n",
        "    def __init__(self, n_channels=64):\n",
        "        'U-net from the paper \"Olaf Ronneberger, Philipp Fischer, and Thomas Brox\": https://arxiv.org/abs/1505.04597 '\n",
        "        super(U_net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,n_channels,3)\n",
        "        self.conv2 = nn.Conv2d(n_channels,n_channels,3)\n",
        "        self.pool = nn.MaxPool2d(2,stride=2)\n",
        "        self.conv3 = nn.Conv2d(n_channels,2*n_channels,3)\n",
        "        self.conv4 = nn.Conv2d(2*n_channels,2*n_channels,3)\n",
        "        self.conv5 = nn.Conv2d(2*n_channels,4*n_channels,3)\n",
        "        self.conv6 = nn.Conv2d(4*n_channels,4*n_channels,3)\n",
        "        self.conv7 = nn.Conv2d(4*n_channels,8*n_channels,3)\n",
        "        self.conv8 = nn.Conv2d(8*n_channels,8*n_channels,3)\n",
        "        self.conv9 = nn.Conv2d(8*n_channels,16*n_channels,3)\n",
        "        self.conv10 = nn.Conv2d(16*n_channels,16*n_channels,3)\n",
        "        #self.upconv1= nn.ConvTranspose2d(16*n_channels,16*n_channels,2)\n",
        "        self.upconv1 = nn.Upsample(scale_factor=2)\n",
        "        self.conv11 = nn.Conv2d(16*n_channels,8*n_channels,3)\n",
        "        self.conv12 = nn.Conv2d(8*n_channels,8*n_channels,3)\n",
        "        #self.upconv2= nn.ConvTranspose2d(8*n_channels,8*n_channels,2)\n",
        "        self.upconv2 = nn.Upsample(scale_factor=2)\n",
        "        self.conv13 = nn.Conv2d(8*n_channels,4*n_channels,3)\n",
        "        self.conv14 = nn.Conv2d(4*n_channels,4*n_channels,3)\n",
        "        #self.upconv3= nn.ConvTranspose2d(4*n_channels,4*n_channels,2)\n",
        "        self.upconv3 = nn.Upsample(scale_factor=2)\n",
        "        self.conv15 = nn.Conv2d(4*n_channels,2*n_channels,3)\n",
        "        self.conv16 = nn.Conv2d(2*n_channels,2*n_channels,3)\n",
        "        #self.upconv4= nn.ConvTranspose2d(2*n_channels,2*n_channels,2)\n",
        "        self.upconv4 = nn.Upsample(scale_factor=2)\n",
        "        self.conv17 = nn.Conv2d(2*n_channels,n_channels,3)\n",
        "        self.conv18 = nn.Conv2d(n_channels,n_channels,3)\n",
        "        self.conv1_1= nn.Conv2d(n_channels,2,1)\n",
        "        self.activation1=nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.pool(self.activation1(self.conv2(self.activation1(self.conv1(x)))))\n",
        "        out = self.pool(self.activation1(self.conv4(self.activation1(self.conv3(out)))))\n",
        "        out = self.pool(self.activation1(self.conv6(self.activation1(self.conv5(out)))))\n",
        "        out = self.pool(self.activation1(self.conv8(self.activation1(self.conv7(out)))))\n",
        "        out = self.activation1(self.conv10(self.activation1(self.conv9(out))))\n",
        "        out = self.upconv1(out)\n",
        "        out = self.activation1(self.conv12(self.activation1(self.conv11(out))))\n",
        "        out = self.upconv2(out)\n",
        "        out = self.activation1(self.conv14(self.activation1(self.conv13(out))))\n",
        "        out = self.upconv3(out)\n",
        "        out = self.activation1(self.conv16(self.activation1(self.conv15(out))))\n",
        "        out = self.upconv4(out)\n",
        "        out = self.activation1(self.conv18(self.activation1(self.conv17(out))))\n",
        "        out = self.conv1_1(out)\n",
        "        return out"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5E9lylozMEC"
      },
      "source": [
        "#Training (adapting function from lab10)\n",
        "def train(model, criterion, X, Y, optimizer, num_epochs, device):\n",
        "  \"\"\"\n",
        "  @param model: torch.nn.Module\n",
        "  @param criterion: torch.nn.modules.loss._Loss\n",
        "  @param image_input: numpy.ndarray\n",
        "  @param labeled_images: numpy.ndarray\n",
        "  @param optimizer: torch.optim.Optimizer\n",
        "  @param num_epochs: int\n",
        "  \"\"\"\n",
        "  \n",
        "\n",
        "  print(\"Starting training\")\n",
        "  #Cycle for epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # Train an epoch\n",
        "    model.train()\n",
        "    for i in range(X.shape[0]):\n",
        "      tensor_X = torch.Tensor(X[i]).view(1,1,in_size,in_size)\n",
        "      tensor_Y = torch.Tensor(Y)[i].view(1,2,out_size,out_size)\n",
        "      tensor_X, tensor_Y = tensor_X.to(device), tensor_Y.to(device)\n",
        "\n",
        "      # Evaluate the network (forward pass)\n",
        "      prediction = model(tensor_X)\n",
        "      loss = criterion(prediction,tensor_Y)\n",
        "      \n",
        "      # Compute the gradient\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "\n",
        "      # Update the parameters of the model with a gradient step\n",
        "      optimizer.step()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEwe6E2gwzys"
      },
      "source": [
        "The loss function used to train the network is CrossEntropy as described in the paper. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsZfLMYfNBMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1350022-a7e4-4aef-b64e-1881ca8200e3"
      },
      "source": [
        "num_epochs=10\n",
        "learning_rate=0.001\n",
        "# batch_size = 1\n",
        "\n",
        "n, in_size, out_size = X.shape[0], 572, 388\n",
        "print(n)\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"Things will go much quicker if you enable a GPU in Colab under 'Runtime / Change Runtime Type'\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# dataset = TensorDataset(torch.Tensor(X).view(n,1,1,in_size,in_size),torch.Tensor(Y).view(n,1,2,out_size,out_size)) # create your datset\n",
        "# dataloader = DataLoader(dataset, shuffle=True, batch_size=batch_size) # create your dataloader\n",
        "\n",
        "model=U_net().to(device)\n",
        "\n",
        "optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.9)\n",
        "criterion = nn.BCEWithLogitsLoss() \n",
        "\n",
        "train(model, criterion, X, Y, optimizer, num_epochs, device) "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57\n",
            "Starting training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQUCUgJpha2d"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}