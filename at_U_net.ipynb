{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "at_U_net.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9-final"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = 'local' # 'local' or 'colab'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "acrcRmmwrwvX"
      },
      "source": [
        "# Import data and packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrozW7WXkFN1"
      },
      "source": [
        "if env=='colab':\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    !cp \"/content/drive/MyDrive/Colab Notebooks/helpers.py\" .\n",
        "    !cp -av \"/content/drive/MyDrive/Colab Notebooks/at_dataset\" ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7cDqXqaGk_A"
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from torch import optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "import glob\n",
        "import cv2 as cv\n",
        "from helpers import *\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GV81YSi0Gk_B"
      },
      "source": [
        "#Accuracy \n",
        "def accuracy(pred, test_labels):\n",
        "    '''\n",
        "    pred: torch.tensor (result of U-net) of size [num_batches=1, 2, dim_image1, dim_image2]\n",
        "    test_labels: torch.tensor (Real labels for the image) \n",
        "    '''\n",
        "    '''\n",
        "    Calculate the percentage of correct pixels labeled\n",
        "    '''\n",
        "    label_pred=torch.argmax(pred,dim=1)\n",
        "    error = (torch.abs(label_pred-test_labels)).mean()\n",
        "    return 1-error \n",
        "\n",
        "#Confussion\n",
        "def confussion(pred, test_labels):\n",
        "    '''\n",
        "    pred: torch.tensor (result of U-net) of size [num_batches=1, 2, dim_image1, dim_image2]\n",
        "    test_labels: torch.tensor (Real labels for the image) \n",
        "    '''\n",
        "    '''\n",
        "    Calculate the percentage of true-positive, true-negative, false-positive, and false-negative\n",
        "    '''\n",
        "    pred_, lbls_ = torch.argmax(pred,dim=1).view(-1), test_labels.view(-1)\n",
        "    TP = torch.sum(torch.logical_and(pred_==1, lbls_==1)) / torch.sum(lbls_==1)\n",
        "    TN = torch.sum(torch.logical_and(pred_==0, lbls_==0)) / torch.sum(lbls_==0)\n",
        "    FP = torch.sum(torch.logical_and(pred_==1, lbls_==0)) / torch.sum(lbls_==0)\n",
        "    FN = torch.sum(torch.logical_and(pred_==0, lbls_==1)) / torch.sum(lbls_==1)\n",
        "\n",
        "    return TP, TN, FP, FN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPeTVdCZKaZg"
      },
      "source": [
        "#Accuracy \n",
        "def accuracy_np(pred, test_labels):\n",
        "    '''\n",
        "    pred: torch.tensor (result of U-net) of size [num_batches=1, 2, dim_image1, dim_image2]\n",
        "    test_labels: torch.tensor (Real labels for the image) \n",
        "    '''\n",
        "    '''\n",
        "    Calculate the percentage of correct pixels labeled\n",
        "    '''\n",
        "    return (pred==test_labels).mean()\n",
        "\n",
        "#Confussion\n",
        "def confussion_np(pred, test_labels):\n",
        "    '''\n",
        "    pred: torch.tensor (result of U-net) of size [num_batches=1, 2, dim_image1, dim_image2]\n",
        "    test_labels: torch.tensor (Real labels for the image) \n",
        "    '''\n",
        "    '''\n",
        "    Calculate the percentage of true-positive, true-negative, false-positive, and false-negative\n",
        "    '''\n",
        "    TP = ((pred==1)*(test_labels==1)).sum() / (test_labels==1).sum()\n",
        "    TN = ((pred==0)*(test_labels==0)).sum() / (test_labels==0).sum()\n",
        "    FP = ((pred==1)*(test_labels==0)).sum() / (test_labels==0).sum()\n",
        "    FN = ((pred==0)*(test_labels==1)).sum() / (test_labels==1).sum()\n",
        "    return TP, TN, FP, FN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH-9vSWJuX_-"
      },
      "source": [
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling and conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.up_conv = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),\n",
        "            nn.ZeroPad2d((0,1,0,1)),\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=2)\n",
        "        )\n",
        "        # self.up_conv = nn.ConvTranspose2d(in_channels , out_channels, kernel_size=2, stride=2)\n",
        "        self.double_conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        # up-conv input\n",
        "        x1 = self.up_conv(x1)\n",
        "\n",
        "        # crop and contatinate\n",
        "        diffY = int((x2.size()[2] - x1.size()[2]) // 2)\n",
        "        diffX = int((x2.size()[3] - x1.size()[3]) // 2)\n",
        "        x2 = x2[:,:,diffY:-diffY, diffX:-diffX]\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1aMnQ24jpGz"
      },
      "source": [
        "class U_net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(U_net, self).__init__()\n",
        "\n",
        "        self.inc = DoubleConv(1, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        self.down4 = Down(512, 1024)\n",
        "        self.up1 = Up(1024, 512)\n",
        "        self.up2 = Up(512, 256)\n",
        "        self.up3 = Up(256, 128)\n",
        "        self.up4 = Up(128, 64)\n",
        "        self.out = OutConv(64, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.out(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5E9lylozMEC"
      },
      "source": [
        "#Training (adapting function from lab10)\n",
        "def train(model, criterion, img_names_train, labels_names_train, optimizer, num_epochs, device):\n",
        "  \"\"\"\n",
        "  @param model: torch.nn.Module\n",
        "  @param criterion: torch.nn.modules.loss._Loss\n",
        "  @param image_input: numpy.ndarray\n",
        "  @param labeled_images: numpy.ndarray\n",
        "  @param optimizer: torch.optim.Optimizer\n",
        "  @param num_epochs: int\n",
        "  \"\"\"\n",
        "  in_size, out_size = 572, 388\n",
        "\n",
        "  print(\"Starting training\")\n",
        "  #Cycle for epochs\n",
        "  for epoch in range(num_epochs):\n",
        "    # Train an epoch\n",
        "    model.train()\n",
        "    for i,img_path in enumerate(img_names_train):\n",
        "      # load individual image and label and segment them\n",
        "      img = [cv.imread(img_path, cv.IMREAD_UNCHANGED)/(2**16-1)]\n",
        "      lbl = [cv.imread(labels_names_train[i], cv.IMREAD_UNCHANGED)]\n",
        "      X, y = segment_dataset(img, lbl, in_size, out_size, extend = True, augment=False)\n",
        "      Y = np.repeat(y[:, np.newaxis, :, :], 2, axis=1).astype(np.float32)\n",
        "      Y[:,0,:,:] = np.abs(Y[:,0,:,:]-1.0)\n",
        "\n",
        "      for j in range(X.shape[0]):\n",
        "        print('\\r', f'epoch: {epoch+1:03d}/{num_epochs:03d}, img: {i+1:03d}/{len(img_names_train):03d}, segment: {j+1:03d}/{X.shape[0]:03d}', end='')\n",
        "        # convert numpy values to tensor form and load to GPU\n",
        "        tensor_X = torch.Tensor(X[j]).view(1,1,in_size,in_size)\n",
        "        tensor_Y = torch.Tensor(Y[j]).view(1,2,out_size,out_size)\n",
        "        tensor_X, tensor_Y = tensor_X.to(device), tensor_Y.to(device)\n",
        "\n",
        "        # Evaluate the network (forward pass)\n",
        "        prediction = model(tensor_X)\n",
        "        loss = criterion(prediction,tensor_Y)\n",
        "        \n",
        "        # Compute the gradient\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters of the model with a gradient step\n",
        "        optimizer.step()\n",
        "\n",
        "  print(\"Training finished!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTZeKjCDVWxq"
      },
      "source": [
        "def test(model, img_names, labels_names, device):\n",
        "  \n",
        "  in_size, out_size = 572, 388\n",
        "  diff_size = int((in_size - in_size) // 2)\n",
        "\n",
        "  model.eval()\n",
        "  # accuracies_test = []\n",
        "  for i,img_path in enumerate(img_names):\n",
        "    # load individual image and label and segment them\n",
        "    img = cv.imread(img_path, cv.IMREAD_UNCHANGED)/(2**16-1)\n",
        "    lbl = cv.imread(labels_names[i], cv.IMREAD_UNCHANGED)\n",
        "    pred = out_predict(model, img, device)\n",
        "\n",
        "    # calculate accuracy and confusion\n",
        "    TP, TN, FP, FN = confussion_np(pred, lbl)\n",
        "    print(f\"Test accuracy: {accuracy_np(pred, lbl):.5f}\")\n",
        "    print(f\"True-Positives: {TP:.5f}, True-Negatives: {TN:.5f}, False-Positives: {FP:.5f}, False-Negatives: {FN:.5f}\")\n",
        "\n",
        "    # plot\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(131)\n",
        "    plt.imshow(img, vmin=0, vmax=1)\n",
        "    plt.axis('off')\n",
        "    plt.title('Original')\n",
        "    plt.subplot(132)\n",
        "    plt.imshow(lbl)\n",
        "    plt.axis('off')\n",
        "    plt.title('Label')\n",
        "    plt.subplot(133)\n",
        "    plt.imshow(pred)\n",
        "    plt.axis('off')\n",
        "    plt.title('Prediction')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wsZfLMYfNBMS",
        "collapsed": true
      },
      "source": [
        "seed = 0\n",
        "num_epochs=10\n",
        "learning_rate=0.0001\n",
        "data_size = 100\n",
        "split = 0.70\n",
        "pkl_name = f'pickle_e{num_epochs}_lr{str(learning_rate)[0]+str(learning_rate)[2:]}_d{int(split*data_size)}.pickle'\n",
        "\n",
        "# split dataset\n",
        "if env == 'colab':\n",
        "  imgs_names = np.array(sorted(glob.glob('/content/at_dataset/images/*.tif')),dtype=object)\n",
        "  labels_names = np.array(sorted(glob.glob('/content/at_dataset/labels/*.tiff')),dtype=object)\n",
        "elif env == 'local':\n",
        "  imgs_names = np.array(sorted(glob.glob('./at_dataset/images/*.tif')),dtype=object)\n",
        "  labels_names = np.array(sorted(glob.glob('./at_dataset/labels/*.tiff')),dtype=object)\n",
        "else: \n",
        "  raise \"Invalid 'env' value\"\n",
        "np.random.seed(seed)\n",
        "idx = np.random.choice(len(imgs_names),data_size)\n",
        "idx_train = idx[:int(split*data_size)]\n",
        "idx_test = idx[int(split*data_size):]\n",
        "img_names_train = imgs_names[idx_train]\n",
        "img_names_test = imgs_names[idx_test]\n",
        "labels_names_train = labels_names[idx_train]\n",
        "labels_names_test = labels_names[idx_test]\n",
        "\n",
        "# set device\n",
        "if not torch.cuda.is_available():\n",
        "  raise Exception(\"Things will go much quicker if you enable a GPU in Colab under 'Runtime / Change Runtime Type'\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model=U_net().to(device)\n",
        "\n",
        "# optimizer = optim.RMSprop(model.parameters(), lr=learning_rate, weight_decay=1e-8, momentum=0.99)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.99)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONj2AYMkZ0XH"
      },
      "source": [
        "# train model\n",
        "train(model, criterion, img_names_train, labels_names_train, optimizer, num_epochs, device)\n",
        "if env == 'colab':\n",
        "    torch.save(model, '/content/drive/MyDrive/Uni/EPFL/MachineLearning/ML_course/projects/project2/'+pkl_name)\n",
        "elif env == 'local':\n",
        "    torch.save(model,'./'+pkl_name)\n",
        "else: \n",
        "  raise \"Invalid 'env' value\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFS7sxGn3y7b",
        "tags": []
      },
      "source": [
        "# test model\n",
        "%reload_ext autoreload\n",
        "if env == 'colab':\n",
        "    model = torch.load('/content/drive/MyDrive/Uni/EPFL/MachineLearning/ML_course/projects/project2/'+pkl_name)\n",
        "elif env == 'local':\n",
        "    model = torch.load('./'+pkl_name)\n",
        "else: \n",
        "  raise \"Invalid 'env' value\"\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "test(model, img_names_test, labels_names_test, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Y1pue8fAaf"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}