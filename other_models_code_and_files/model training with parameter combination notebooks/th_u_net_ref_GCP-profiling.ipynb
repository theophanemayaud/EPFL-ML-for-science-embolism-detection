{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKbc3s9LoKC8"
   },
   "source": [
    "# UNet implementation with complementary tools to try different approaches\n",
    "Based on https://youtu.be/u1loyDCoGbE for implementation of U-net : https://arxiv.org/pdf/1505.04597.pdf\n",
    "\n",
    "This notebook is the reference notebook of our implementation, and we will make copies of it, to test different small changes and compare their results.\n",
    "\n",
    "See cell 6 for general parameters which will change frequently. Otherwise changes will be details here in this cell.\n",
    "\n",
    "## Specific test details\n",
    "\n",
    "This is an optimized version for google cloud platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Platform install of dependencies\n",
    "# %pip install numpy\n",
    "# %pip install torch\n",
    "# %pip install glob\n",
    "# %pip install opencv-python\n",
    "# %pip install time\n",
    "# %pip install matplotlib.\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "dtCj1z1-oKDE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3JLUi4s1Dkzf"
   },
   "outputs": [],
   "source": [
    "env = \"gcp\" # local or colab or gcp\n",
    "train_or_load = \"train\" # train or load : Are we training a model, or just loading a pretrained one ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FzWBgbHoKDF",
    "outputId": "c4d30fb9-5946-48ba-876e-a6a0d8bf88af"
   },
   "outputs": [],
   "source": [
    "#Google Colab specifics\n",
    "if env == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    !cp \"/content/drive/MyDrive/helpers.py\" .\n",
    "    imgs_names = glob.glob( '/content/drive/MyDrive/th_analysedimages/*.tif')\n",
    "    labels_names = glob.glob('/content/drive/MyDrive/labels/*.png')\n",
    "elif env == \"gcp\":\n",
    "    imgs_names = glob.glob( '/home/jupyter/cs-433-project-2-ml_fools/th_analysedimages/*.tif')\n",
    "    labels_names = glob.glob('/home/jupyter/cs-433-project-2-ml_fools/th_csv_labels/png_masks_emb/*.png')\n",
    "    !cp \"/home/jupyter/cs-433-project-2-ml_fools/helpers.py\" .\n",
    "#Local github project specifics\n",
    "elif env == \"local\":\n",
    "    imgs_names = glob.glob( '/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/th_analysedimages/*.tif')\n",
    "    labels_names = glob.glob('/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/th_csv_labels/png_masks_emb/*.png')\n",
    "    !cp \"/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/helpers.py\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIo9U3weoKDH",
    "outputId": "8788c4ce-e306-4f73-d0ec-419cfab39370"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 357 images\n",
      "Found 357 labels\n"
     ]
    }
   ],
   "source": [
    "from helpers import png_to_mask, segment_dataset, compute_emb_surf_pred_error, confusion, out_predict\n",
    "\n",
    "imgs_names= sorted(imgs_names)\n",
    "#imgs = [cv.imread(name, cv.IMREAD_UNCHANGED) for name in imgs_names[1]]\n",
    "print(f\"Found {len(imgs_names)} images\")\n",
    "\n",
    "labels_names= sorted(labels_names)\n",
    "#labels = [png_to_mask(cv.imread(name, cv.IMREAD_UNCHANGED)) for name in labels_names]\n",
    "print(f\"Found {len(labels_names)} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters are here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration parameters\n",
    "learning_rate = 1e-3\n",
    "\n",
    "num_epochs=2\n",
    "number_of_images = 1\n",
    "train_img_pathnames = imgs_names[:number_of_images]\n",
    "train_label_pathnames = labels_names[:number_of_images]\n",
    "\n",
    "disp_every_x_epoch = 10\n",
    "disp_every_x_img = 10\n",
    "max_seg_to_disp = 0    # NB 1 (and not 0) means the first segment is displayed\n",
    "disp_every_x_seg = 1\n",
    "\n",
    "print_images_while_training = False\n",
    "\n",
    "# Testing predictions parameters\n",
    "test_img_start = 300\n",
    "test_img_stop = 305\n",
    "test_img_pathnames = imgs_names[test_img_start:test_img_stop]\n",
    "test_label_pathnames = labels_names[test_img_start:test_img_stop]\n",
    "\n",
    "print_each_test_stat = False\n",
    "print_each_test_img = False\n",
    "\n",
    "# Saving parameters when in train mode\n",
    "model_name = \"PlaceHolderModelName\"\n",
    "model_description = \"PlaceHolderModelDescription\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK-k0p8PoKDH"
   },
   "source": [
    "UNet picture representation : \n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRxFnJdmC707",
    "outputId": "290bd142-57fe-4df0-d60f-0e9cf8e6721b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device is: cuda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the device to train on, if a GPU is available (ex when on Google Colab)\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Things will go much quicker if you enable a GPU, ex in Colab under 'Runtime / Change Runtime Type'\")\n",
    "else:\n",
    "    #del model # only needed when re-running multiple times\n",
    "    torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Selected device is: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fscs-r1JoKDH"
   },
   "outputs": [],
   "source": [
    "# UNet definitions\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # functions for going down the U\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.d_double_conv_1 = double_conv(1, 64)\n",
    "        self.d_double_conv_2 = double_conv(64, 128)\n",
    "        self.d_double_conv_3 = double_conv(128, 256)\n",
    "        self.d_double_conv_4 = double_conv(256, 512)\n",
    "        self.d_double_conv_5 = double_conv(512, 1024)\n",
    "        \n",
    "        # functions for going up the U\n",
    "        self.up_trans_4 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)        \n",
    "        self.u_double_conv_4 = double_conv(1024, 512)\n",
    "        self.up_trans_3 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_3 = double_conv(512, 256)\n",
    "        self.up_trans_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_2 = double_conv(256, 128)\n",
    "        self.up_trans_1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_1 = double_conv(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        '''makes the 388x388 prediction with the model, image must be 572x572pixels'''\n",
    "        \n",
    "        # Going down the U\n",
    "        d1 = self.d_double_conv_1(image) # first \"level\"\n",
    "        # print(x1.size())\n",
    "        x = self.max_pool_2x2(d1)\n",
    "        d2 = self.d_double_conv_2(x) # second\n",
    "        x = self.max_pool_2x2(d2)\n",
    "        d3 = self.d_double_conv_3(x) # third\n",
    "        x = self.max_pool_2x2(d3)\n",
    "        d4 = self.d_double_conv_4(x) # fourth\n",
    "        x = self.max_pool_2x2(d4)\n",
    "        x = self.d_double_conv_5(x) # last layer (fifth) : no max pool\n",
    "        # plt.imshow(x.detach().numpy()[0, 0, :, :])\n",
    "        \n",
    "        # Going up the U\n",
    "        x = self.up_trans_4(x)\n",
    "        d4 = crop_img(tensor=d4, target_tensor=x) #crop to copy\n",
    "        x = self.u_double_conv_4(torch.cat([d4, x], 1))\n",
    "        \n",
    "        x = self.up_trans_3(x)\n",
    "        d3 = crop_img(tensor=d3, target_tensor=x)\n",
    "        x = self.u_double_conv_3(torch.cat([d3, x], 1))\n",
    "        \n",
    "        x = self.up_trans_2(x)\n",
    "        d2 = crop_img(tensor=d2, target_tensor=x)\n",
    "        x = self.u_double_conv_2(torch.cat([d2, x], 1))\n",
    "        \n",
    "        x = self.up_trans_1(x)\n",
    "        d1 = crop_img(tensor=d1, target_tensor=x)\n",
    "        x = self.u_double_conv_1(torch.cat([d1, x], 1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    \n",
    "# some functions so reduce redunduncy\n",
    "def double_conv(nb_in_channels, nb_out_channels): # Used for every descending step\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(nb_in_channels, nb_out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(nb_out_channels, nb_out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "def crop_img(tensor, target_tensor): # Used for copy and crop between descending and ascending\n",
    "    target_size = target_tensor.size()[2] # NB they are square so .size[2]=.size[3]\n",
    "    tensor_size = tensor.size()[2]\n",
    "    delta = tensor_size - target_size #target is always smaller\n",
    "    pix_crop = delta // 2\n",
    "    return tensor[:, :, pix_crop:tensor_size-pix_crop, pix_crop:tensor_size-pix_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "MPu2o3zAoKDI"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, img_pathnames, label_pathnames, criterion, optimizer, device, num_epochs=25, \n",
    "                disp_every_x_epoch = 1,\n",
    "                disp_every_x_img = 1,\n",
    "                max_seg_to_disp = 100, # NB 1 (and not 0) means the first segment is displayed\n",
    "                disp_every_x_seg = 1):\n",
    "    points=0 # incrementer for displaying progress\n",
    "    train_start_time = time.process_time() # For process monitoring\n",
    "\n",
    "    print(\"Starting the training on images !\")\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for image_i in range(len(img_pathnames)):\n",
    "            image = cv.imread(img_pathnames[image_i], cv.IMREAD_UNCHANGED)\n",
    "            label = png_to_mask(cv.imread(label_pathnames[image_i], cv.IMREAD_UNCHANGED))\n",
    "            \n",
    "            image_segments, label_segments = segment_dataset([image], [label])\n",
    "            \n",
    "            for segment_i in range(len(image_segments[:, 0, 0])):\n",
    "                since = time.process_time() # For process monitoring\n",
    "                img_seg = torch.tensor(image_segments[segment_i, :, :], requires_grad=True).view(1, 1, 572, 572).to(device).float()\n",
    "                \n",
    "                profiling = time.process_time()-since\n",
    "                print(f\"\\nImg segment tensor creation took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "                \n",
    "                label_seg = torch.tensor(label_segments[segment_i, :, :].astype(float)).view(1, 388, 388).to(device).long()\n",
    "                \n",
    "                profiling = time.process_time()-profiling\n",
    "                print(f\"Label segment tensor creation took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "\n",
    "                prediction = model(img_seg)\n",
    "                \n",
    "                profiling = time.process_time()-profiling\n",
    "                print(f\"Making prediction took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "\n",
    "                loss = criterion(prediction, label_seg)\n",
    "                \n",
    "                profiling = time.process_time()-profiling\n",
    "                print(f\"Calculating loss took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "            \n",
    "                # Compute the gradient\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                profiling = time.process_time()-profiling\n",
    "                print(f\"Making gradient 0 took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                profiling = time.process_time()-profiling\n",
    "                print(f\"Calculating backward took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "                \n",
    "                # Update the parameters of the model with a gradient step\n",
    "                optimizer.step()\n",
    "                \n",
    "                profiling = time.process_time()-profiling\n",
    "                print(f\"Doing step took {round(1000*profiling,2)}ms\")\n",
    "                profiling = time.process_time()\n",
    "                            \n",
    "                # Optionnaly display status during training\n",
    "                if ( epoch%disp_every_x_epoch==0 and image_i%disp_every_x_img==0 \n",
    "                        and segment_i%disp_every_x_seg==0 and segment_i<max_seg_to_disp ): \n",
    "                    if image_i==0 and segment_i==0:\n",
    "                        print(f\"\\nEpoch {1+epoch}/{num_epochs}\", end=\"\")\n",
    "                    if segment_i==0:\n",
    "                        print(f\"\\n|  Image {1+image_i}/{len(img_pathnames)} '{img_pathnames[image_i]}'\", end=\"\")\n",
    "                \n",
    "                    time_elapsed = time.process_time()-since\n",
    "\n",
    "                    # Make new prediction so compare before and after step\n",
    "                    new_prediction = model(img_seg)\n",
    "                    new_loss = criterion(new_prediction, label_seg)\n",
    "                    ori_lab_seg = label_seg.cpu().detach().numpy()[0,:,:].astype(int)\n",
    "                    pred_lab_seg = torch.argmax(prediction, dim=1).cpu().detach().numpy()[0, :, :]\n",
    "\n",
    "                    emb_surf_pred_error = compute_emb_surf_pred_error(ori_lab_seg, pred_lab_seg, print_values=False)\n",
    "                    print(f\"\\n|  |  Segment {1+segment_i}/{len(image_segments[:, 0, 0])} : loss={loss} \"+\\\n",
    "                          f\"duration={int(time_elapsed)//60}m {int(time_elapsed%60)}s {int(1000*(time_elapsed-int(time_elapsed)))}ms. Loss reduced {loss-new_loss}. \"+\\\n",
    "                          f\"Emb surf pred err= {emb_surf_pred_error}%\", end=\"\")\n",
    "                        \n",
    "                    # # Also optionally print confusion values :\n",
    "                    # print(f\"\\n|  |  Confusion values are :{confusion(ori_lab_seg, pred_lab_seg, data_type='numpy')}\")\n",
    "                    \n",
    "                    # Also optionnaly print image segment, label and prediction\n",
    "                    if print_images_while_training == True:\n",
    "                        _ , axs = plt.subplots(ncols=3, figsize=(40, 40))\n",
    "                        axs[0].set_title(\"Segment of original image\")\n",
    "                        axs[0].imshow(img_seg.cpu().detach().numpy()[0,0,:,:])\n",
    "                        axs[1].set_title(\"Segment of original label\")\n",
    "                        axs[1].imshow(label_seg.cpu().detach().numpy()[0,:,:])\n",
    "                        axs[2].set_title(\"Predicted label segment\")\n",
    "                        axs[2].imshow(torch.argmax(prediction, dim=1).cpu().detach().numpy()[0,:,:])\n",
    "                        plt.show()\n",
    "                    \n",
    "                    points=0\n",
    "\n",
    "                if ( (epoch%disp_every_x_epoch==0 and image_i%disp_every_x_img==1 and segment_i==0) \n",
    "                        or (epoch%disp_every_x_epoch==1 and points==0) ):\n",
    "                    print(\"\\n   ...Next epochs & images \", end=\"\")\n",
    "                    points = 1\n",
    "                else:\n",
    "                    print(\".\", end=\"\")\n",
    "                    points = points+1 \n",
    "                    if  points>100:\n",
    "                        print(\"\\n      ...\", end=\"\")\n",
    "                        points = 1\n",
    "                        \n",
    "                time_elapsed = time.process_time()-since\n",
    "                print(f\"\\nComplete segment loop took {round(1000*time_elapsed,2)}ms\")\n",
    "                        \n",
    "    time_elapsed = time.process_time()-train_start_time\n",
    "    print(f\"\\n\\n Finished training after {int(time_elapsed)//60}m {int(time_elapsed%60)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxvycGsWoKDJ",
    "outputId": "01ec10c1-12b5-4b63-9e77-dea48ed70fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training on images !\n",
      "\n",
      "Img segment tensor creation took 1.53ms\n",
      "Label segment tensor creation took 1.27ms\n",
      "Making prediction took 35.02ms\n",
      "Calculating loss took 0.67ms\n",
      "Making gradient 0 took 0.31ms\n",
      "Calculating backward took 427.24ms\n",
      "Doing step took 8.84ms\n",
      ".\n",
      "Complete segment loop took 475.63ms\n",
      "\n",
      "Img segment tensor creation took 39.99ms\n",
      "Label segment tensor creation took 2.29ms\n",
      "Making prediction took 8.35ms\n",
      "Calculating loss took 0.51ms\n",
      "Making gradient 0 took 1.67ms\n",
      "Calculating backward took 508.65ms\n",
      "Doing step took 8.43ms\n",
      ".\n",
      "Complete segment loop took 575.14ms\n",
      "\n",
      "Img segment tensor creation took 34.28ms\n",
      "Label segment tensor creation took 2.18ms\n",
      "Making prediction took 9.53ms\n",
      "Calculating loss took 0.34ms\n",
      "Making gradient 0 took 6.21ms\n",
      "Calculating backward took 504.74ms\n",
      "Doing step took 9.02ms\n",
      ".\n",
      "Complete segment loop took 569.37ms\n",
      "\n",
      "Img segment tensor creation took 34.91ms\n",
      "Label segment tensor creation took 2.15ms\n",
      "Making prediction took 8.79ms\n",
      "Calculating loss took 0.62ms\n",
      "Making gradient 0 took 6.07ms\n",
      "Calculating backward took 508.67ms\n",
      "Doing step took 8.61ms\n",
      ".\n",
      "Complete segment loop took 570.69ms\n",
      "\n",
      "Img segment tensor creation took 35.02ms\n",
      "Label segment tensor creation took 2.23ms\n",
      "Making prediction took 12.59ms\n",
      "Calculating loss took 0.6ms\n",
      "Making gradient 0 took 2.13ms\n",
      "Calculating backward took 500.97ms\n",
      "Doing step took 8.07ms\n",
      ".\n",
      "Complete segment loop took 562.9ms\n",
      "\n",
      "Img segment tensor creation took 34.51ms\n",
      "Label segment tensor creation took 2.25ms\n",
      "Making prediction took 12.84ms\n",
      "Calculating loss took 0.34ms\n",
      "Making gradient 0 took 1.98ms\n",
      "Calculating backward took 496.09ms\n",
      "Doing step took 8.69ms\n",
      ".\n",
      "Complete segment loop took 557.83ms\n",
      "\n",
      "Img segment tensor creation took 2.11ms\n",
      "Label segment tensor creation took 0.91ms\n",
      "Making prediction took 9.02ms\n",
      "Calculating loss took 0.74ms\n",
      "Making gradient 0 took 2.72ms\n",
      "Calculating backward took 490.22ms\n",
      "Doing step took 8.66ms\n",
      ".\n",
      "Complete segment loop took 521.63ms\n",
      "\n",
      "Img segment tensor creation took 33.86ms\n",
      "Label segment tensor creation took 4.11ms\n",
      "Making prediction took 9.48ms\n",
      "Calculating loss took 0.55ms\n",
      "Making gradient 0 took 6.11ms\n",
      "Calculating backward took 493.72ms\n",
      "Doing step took 5.8ms\n",
      ".\n",
      "Complete segment loop took 555.04ms\n",
      "\n",
      "Img segment tensor creation took 40.06ms\n",
      "Label segment tensor creation took 2.3ms\n",
      "Making prediction took 4.06ms\n",
      "Calculating loss took 0.52ms\n",
      "Making gradient 0 took 1.67ms\n",
      "Calculating backward took 501.48ms\n",
      "Doing step took 6.03ms\n",
      ".\n",
      "Complete segment loop took 562.93ms\n",
      "\n",
      "Img segment tensor creation took 40.15ms\n",
      "Label segment tensor creation took 2.2ms\n",
      "Making prediction took 6.78ms\n",
      "Calculating loss took 0.48ms\n",
      "Making gradient 0 took 5.64ms\n",
      "Calculating backward took 499.38ms\n",
      "Doing step took 7.48ms\n",
      ".\n",
      "Complete segment loop took 562.8ms\n",
      "\n",
      "Img segment tensor creation took 36.0ms\n",
      "Label segment tensor creation took 6.15ms\n",
      "Making prediction took 7.98ms\n",
      "Calculating loss took 0.47ms\n",
      "Making gradient 0 took 1.65ms\n",
      "Calculating backward took 506.38ms\n",
      "Doing step took 5.89ms\n",
      ".\n",
      "Complete segment loop took 565.21ms\n",
      "\n",
      "Img segment tensor creation took 41.4ms\n",
      "Label segment tensor creation took 2.22ms\n",
      "Making prediction took 7.7ms\n",
      "Calculating loss took 0.66ms\n",
      "Making gradient 0 took 1.52ms\n",
      "Calculating backward took 509.46ms\n",
      "Doing step took 5.92ms\n",
      ".\n",
      "Complete segment loop took 569.99ms\n",
      "\n",
      "\n",
      " Finished training after 0m 6s\n"
     ]
    }
   ],
   "source": [
    "# Actually training the model\n",
    "if train_or_load == \"train\" : \n",
    "    \n",
    "    model = UNet().to(device)\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_model(model, train_img_pathnames, train_label_pathnames, criterion, optimizer, device, num_epochs,\n",
    "                disp_every_x_epoch,\n",
    "                disp_every_x_img,\n",
    "                max_seg_to_disp,\n",
    "                disp_every_x_seg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nsFNNge0h3eZ"
   },
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "if train_or_load == \"load\":  \n",
    "    PATH = \"/content/drive/MyDrive/savedmodels/\" + model_name + \".pkl\"\n",
    "    if env == \"local\" or env == \"gcp\":\n",
    "        PATH = \"./savedmodels/\" + model_name + \".pkl\"\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        map_to_device = \"cuda:0\"\n",
    "    else:\n",
    "        map_to_device = \"cpu\"\n",
    "\n",
    "    model = UNet()\n",
    "\n",
    "    checkpoint = torch.load(PATH)\n",
    "\n",
    "    print(\"Model parameters are :\")\n",
    "    print(f\"   name : {checkpoint['name']}\")\n",
    "    print(f\"   description : {checkpoint['description']}\")\n",
    "    print(f\"   Model details dump : {checkpoint['model_details_dump']}\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    # # If wanting to resume training :\n",
    "    # optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "    # optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    model.to(device)\n",
    "    print(\"Model successfully loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "Sc0iyD5toKDJ",
    "outputId": "f656ba85-d1ab-47b6-ed43-0c2f139b3b82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testing predictions \n",
      "\n",
      "."
     ]
    }
   ],
   "source": [
    "# Test predictions\n",
    "def test_predictions(model, test_img_pathnames, test_label_pathnames):\n",
    "    emb_surf_pred_errors_list = []\n",
    "\n",
    "    print(\"Starting testing predictions \\n\")\n",
    "\n",
    "    for img_i in range(len(test_img_pathnames)):\n",
    "        test_img = cv.imread(test_img_pathnames[img_i], cv.IMREAD_UNCHANGED)\n",
    "        test_label = png_to_mask(cv.imread(test_label_pathnames[img_i], cv.IMREAD_UNCHANGED))\n",
    "\n",
    "        pred_label = out_predict(model, test_img, device)\n",
    "\n",
    "        emb_surf_pred_error = compute_emb_surf_pred_error(test_label, pred_label, print_values=False)\n",
    "        if print_each_test_stat == True:\n",
    "            print(f\"Emb surf pred err={emb_surf_pred_error}%\")\n",
    "            print(f\"Confusion values are :{confusion(pred_label, test_label, data_type='numpy')}\")\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "        emb_surf_pred_errors_list.append(emb_surf_pred_error)\n",
    "\n",
    "        if img_i == len(test_img_pathnames)-1 or print_each_test_img == True:\n",
    "            print(\"\\nLast image looks like :\")\n",
    "            _ , axs = plt.subplots(ncols=3, figsize=(40, 40))\n",
    "\n",
    "            axs[0].set_title(\"Original image\")\n",
    "            axs[0].imshow(test_img)\n",
    "\n",
    "            axs[1].set_title(\"Original label\")\n",
    "            axs[1].imshow(test_label)\n",
    "\n",
    "            axs[2].set_title(\"Model predicted label\")\n",
    "            axs[2].imshow(pred_label)\n",
    "            plt.show()\n",
    "\n",
    "    # Draw histogram with boxplot of surface error values\n",
    "    sns.set(style=\"ticks\")\n",
    "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                        gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "    f.suptitle(f\"Surface error distribution for {test_img_stop-test_img_start} test images\")\n",
    "    sns.boxplot(x=emb_surf_pred_errors_list, ax=ax_box)\n",
    "    sns.histplot(x=emb_surf_pred_errors_list, ax=ax_hist)\n",
    "    ax_box.set(yticks=[])\n",
    "    sns.despine(ax=ax_hist)\n",
    "    sns.despine(ax=ax_box, left=True)\n",
    "    plt.show()\n",
    "    plt.style.use('default')\n",
    "\n",
    "    print(f\"Finished testing with mean surface error={np.mean(emb_surf_pred_errors_list)}%\")\n",
    "    \n",
    "test_predictions(model, test_img_pathnames, test_label_pathnames)\n",
    "\n",
    "if train_or_load == \"train\":\n",
    "    print(\"\\n\\nCheck of performance on training set :\")\n",
    "    test_predictions(model, train_img_pathnames, train_label_pathnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "js_Ac9KAoKDK"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "if train_or_load == \"train\":\n",
    "    print(f\"Remember to set a model name that makes it easy to identify\")\n",
    "    print(f\"Here are the notebook parameters : \\ncriterion={criterion} \\noptimizer={optimizer} \\nlr={learning_rate}, \\nepochs={num_epochs}\")\n",
    "    \n",
    "    PATH = \"/content/drive/MyDrive/savedmodels/\" + model_name + \".pkl\"\n",
    "    if env == \"local\" or env == \"gcp\":\n",
    "        PATH = \"./savedmodels/\" + model_name + \".pkl\"\n",
    "\n",
    "    print(\"\\nmodel_name = \" + model_name)\n",
    "    print(\"model_description = \" + model_description)\n",
    "    print(\"PATH = \" + PATH)\n",
    "    # Warning : only save once name and descriptions are set correctly\n",
    "    torch.save({\n",
    "            'name': model_name,\n",
    "            'description': model_description,\n",
    "            'model_details_dump': f\"env={env}, train_or_load={train_or_load}, learning rate={learning_rate}, epochs={num_epochs}, optimizer={optimizer}, criterion={criterion}\",         \n",
    "            'model_state_dict': model.state_dict(),\n",
    "            # 'optimizer_state_dict': optimizer.state_dict(), # Only needed when planning to resume training from loaded model\n",
    "            }, PATH)\n",
    "    print(\"Model saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "th_u_net_ref_for_tests.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cu110.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
