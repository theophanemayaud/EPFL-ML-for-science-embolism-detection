{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKbc3s9LoKC8"
   },
   "source": [
    "# UNet implementation with complementary tools to try different approaches\n",
    "Based on https://youtu.be/u1loyDCoGbE for implementation of U-net : https://arxiv.org/pdf/1505.04597.pdf\n",
    "\n",
    "This notebook is the reference notebook of our implementation, and we will make copies of it, to test different small changes and compare their results.\n",
    "\n",
    "See cell 6 for general parameters which will change frequently. Otherwise changes will be details here in this cell.\n",
    "\n",
    "## Specific test details\n",
    "\n",
    "This is an optimized version for google cloud platform but now running batches of more than 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Cloud Platform install of dependencies\n",
    "# %pip install numpy\n",
    "# %pip install torch\n",
    "# %pip install glob\n",
    "# %pip install opencv-python\n",
    "# %pip install time\n",
    "# %pip install matplotlib.\n",
    "# %pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dtCj1z1-oKDE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JLUi4s1Dkzf"
   },
   "outputs": [],
   "source": [
    "env = \"gcp\" # local or colab or gcp\n",
    "train_or_load = \"resume\" # train, load or resume : Are we training a model, or just loading a pretrained one ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FzWBgbHoKDF",
    "outputId": "c4d30fb9-5946-48ba-876e-a6a0d8bf88af"
   },
   "outputs": [],
   "source": [
    "#Google Colab specifics\n",
    "if env == \"colab\":\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "    !cp \"/content/drive/MyDrive/helpers.py\" .\n",
    "    imgs_names = glob.glob( '/content/drive/MyDrive/th_analysedimages/*.tif')\n",
    "    labels_names = glob.glob('/content/drive/MyDrive/labels/*.png')\n",
    "elif env == \"gcp\":\n",
    "    imgs_names = glob.glob( '/home/jupyter/cs-433-project-2-ml_fools/th_analysedimages/*.tif')\n",
    "    labels_names = glob.glob('/home/jupyter/cs-433-project-2-ml_fools/th_csv_labels/png_masks_emb/*.png')\n",
    "    !cp \"/home/jupyter/cs-433-project-2-ml_fools/helpers.py\" .\n",
    "#Local github project specifics\n",
    "elif env == \"local\":\n",
    "    imgs_names = glob.glob( '/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/th_analysedimages/*.tif')\n",
    "    labels_names = glob.glob('/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/th_csv_labels/png_masks_emb/*.png')\n",
    "    !cp \"/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/helpers.py\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIo9U3weoKDH",
    "outputId": "8788c4ce-e306-4f73-d0ec-419cfab39370"
   },
   "outputs": [],
   "source": [
    "from helpers import png_to_mask, segment_dataset, compute_emb_surf_pred_error, confusion, out_predict\n",
    "\n",
    "imgs_names= sorted(imgs_names)\n",
    "#imgs = [cv.imread(name, cv.IMREAD_UNCHANGED) for name in imgs_names[1]]\n",
    "print(f\"Found {len(imgs_names)} images\")\n",
    "\n",
    "labels_names= sorted(labels_names)\n",
    "#labels = [png_to_mask(cv.imread(name, cv.IMREAD_UNCHANGED)) for name in labels_names]\n",
    "print(f\"Found {len(labels_names)} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General parameters are here :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration parameters\n",
    "learning_rate = 1e-3\n",
    "max_batch_size = 5\n",
    "\n",
    "num_epochs = 100\n",
    "number_of_images = 1\n",
    "train_img_pathnames = imgs_names[:number_of_images]\n",
    "train_label_pathnames = labels_names[:number_of_images]\n",
    "\n",
    "disp_every_x_epoch = 10\n",
    "disp_every_x_img = 1\n",
    "max_seg_to_disp = 1    # NB 1 (and not 0) means the first segment is displayed\n",
    "disp_every_x_seg = 1\n",
    "\n",
    "print_images_while_training = True\n",
    "\n",
    "# Testing predictions parameters\n",
    "test_img_start = 300\n",
    "test_img_stop = 310\n",
    "test_img_pathnames = imgs_names[test_img_start:test_img_stop]\n",
    "test_label_pathnames = labels_names[test_img_start:test_img_stop]\n",
    "\n",
    "print_each_test_stat = True\n",
    "print_each_test_img = True\n",
    "\n",
    "# Saving parameters when in train mode\n",
    "save_for_resume = True # takes ~3x more space\n",
    "model_name = \"PlaceHolderModelName\"\n",
    "model_description = \"PlaceHolderModelDescription\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK-k0p8PoKDH"
   },
   "source": [
    "UNet picture representation : \n",
    "\n",
    "<img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pRxFnJdmC707",
    "outputId": "290bd142-57fe-4df0-d60f-0e9cf8e6721b"
   },
   "outputs": [],
   "source": [
    "# Define the device to train on, if a GPU is available (ex when on Google Colab)\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Things will go much quicker if you enable a GPU, ex in Colab under 'Runtime / Change Runtime Type'\")\n",
    "else:\n",
    "    #del model # only needed when re-running multiple times\n",
    "    torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Selected device is: {device}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fscs-r1JoKDH"
   },
   "outputs": [],
   "source": [
    "# UNet definitions\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # functions for going down the U\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.d_double_conv_1 = double_conv(1, 64)\n",
    "        self.d_double_conv_2 = double_conv(64, 128)\n",
    "        self.d_double_conv_3 = double_conv(128, 256)\n",
    "        self.d_double_conv_4 = double_conv(256, 512)\n",
    "        self.d_double_conv_5 = double_conv(512, 1024)\n",
    "        \n",
    "        # functions for going up the U\n",
    "        self.up_trans_4 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)        \n",
    "        self.u_double_conv_4 = double_conv(1024, 512)\n",
    "        self.up_trans_3 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_3 = double_conv(512, 256)\n",
    "        self.up_trans_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_2 = double_conv(256, 128)\n",
    "        self.up_trans_1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_1 = double_conv(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
    "        \n",
    "    def forward(self, image):\n",
    "        '''makes the 388x388 prediction with the model, image must be 572x572pixels'''\n",
    "        \n",
    "        # Going down the U\n",
    "        d1 = self.d_double_conv_1(image) # first \"level\"\n",
    "        # print(x1.size())\n",
    "        x = self.max_pool_2x2(d1)\n",
    "        d2 = self.d_double_conv_2(x) # second\n",
    "        x = self.max_pool_2x2(d2)\n",
    "        d3 = self.d_double_conv_3(x) # third\n",
    "        x = self.max_pool_2x2(d3)\n",
    "        d4 = self.d_double_conv_4(x) # fourth\n",
    "        x = self.max_pool_2x2(d4)\n",
    "        x = self.d_double_conv_5(x) # last layer (fifth) : no max pool\n",
    "        # plt.imshow(x.detach().numpy()[0, 0, :, :])\n",
    "        \n",
    "        # Going up the U\n",
    "        x = self.up_trans_4(x)\n",
    "        d4 = crop_img(tensor=d4, target_tensor=x) #crop to copy\n",
    "        x = self.u_double_conv_4(torch.cat([d4, x], 1))\n",
    "        \n",
    "        x = self.up_trans_3(x)\n",
    "        d3 = crop_img(tensor=d3, target_tensor=x)\n",
    "        x = self.u_double_conv_3(torch.cat([d3, x], 1))\n",
    "        \n",
    "        x = self.up_trans_2(x)\n",
    "        d2 = crop_img(tensor=d2, target_tensor=x)\n",
    "        x = self.u_double_conv_2(torch.cat([d2, x], 1))\n",
    "        \n",
    "        x = self.up_trans_1(x)\n",
    "        d1 = crop_img(tensor=d1, target_tensor=x)\n",
    "        x = self.u_double_conv_1(torch.cat([d1, x], 1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    \n",
    "# some functions so reduce redunduncy\n",
    "def double_conv(nb_in_channels, nb_out_channels): # Used for every descending step\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(nb_in_channels, nb_out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(nb_out_channels, nb_out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "def crop_img(tensor, target_tensor): # Used for copy and crop between descending and ascending\n",
    "    target_size = target_tensor.size()[2] # NB they are square so .size[2]=.size[3]\n",
    "    tensor_size = tensor.size()[2]\n",
    "    delta = tensor_size - target_size #target is always smaller\n",
    "    pix_crop = delta // 2\n",
    "    return tensor[:, :, pix_crop:tensor_size-pix_crop, pix_crop:tensor_size-pix_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MPu2o3zAoKDI"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_model(model, img_pathnames, label_pathnames, criterion, optimizer, device, num_epochs=25, \n",
    "                disp_every_x_epoch = 1,\n",
    "                disp_every_x_img = 1,\n",
    "                max_seg_to_disp = 100, # NB 1 (and not 0) means the first segment is displayed\n",
    "                disp_every_x_seg = 1,\n",
    "                previous_epochs = 0):\n",
    "    points=0 # incrementer for displaying progress\n",
    "    train_start_time = time.process_time() # For process monitoring\n",
    "\n",
    "    print(\"Starting the training on images !\")\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for image_i in range(len(img_pathnames)):\n",
    "            image = cv.imread(img_pathnames[image_i], cv.IMREAD_UNCHANGED)\n",
    "            label = png_to_mask(cv.imread(label_pathnames[image_i], cv.IMREAD_UNCHANGED))\n",
    "            \n",
    "            image_segments, label_segments = segment_dataset([image], [label])\n",
    "            \n",
    "            segment_i = 0\n",
    "            while segment_i < len(image_segments[:, 0, 0]):\n",
    "                updated_segment_i = segment_i\n",
    "                since = time.process_time() # For process monitoring\n",
    "                \n",
    "#                 img_seg = torch.tensor(image_segments[segment_i, :, :], requires_grad=True, dtype = torch.float, device = device).view(1, 1, 572, 572)\n",
    "#                 label_seg = torch.tensor(label_segments[segment_i, :, :].astype(float), requires_grad=False, dtype = torch.long, device = device).view(1, 388, 388)\n",
    "                next_batch_size = max_batch_size\n",
    "                if next_batch_size > len(image_segments[:, 0, 0])-segment_i:\n",
    "                    next_batch_size = len(image_segments[:, 0, 0])-segment_i\n",
    "                img_seg = torch.tensor(image_segments[segment_i:segment_i+next_batch_size, :, :],requires_grad=True, dtype = torch.float, device = device).view(next_batch_size, 1, 572, 572)\n",
    "                label_seg = torch.tensor(label_segments[segment_i:segment_i+next_batch_size, :, :].astype(float), requires_grad=False, dtype = torch.long, device = device).view(next_batch_size, 388, 388)\n",
    "                updated_segment_i = segment_i+next_batch_size-1\n",
    "                \n",
    "                prediction = model(img_seg)\n",
    "                \n",
    "                loss = criterion(prediction, label_seg)\n",
    "            \n",
    "                # Compute the gradient\n",
    "                optimizer.zero_grad()\n",
    "                                \n",
    "                loss.backward()\n",
    "                                \n",
    "                # Update the parameters of the model with a gradient step\n",
    "                optimizer.step()\n",
    "                            \n",
    "                # Optionnaly display status during training\n",
    "                if ( epoch%disp_every_x_epoch==0 and image_i%disp_every_x_img==0 \n",
    "                        and segment_i%disp_every_x_seg==0 and segment_i<max_seg_to_disp ): \n",
    "                    if image_i==0 and segment_i==0:\n",
    "                        print(f\"\\nEpoch {1+epoch + previous_epochs}/{num_epochs+previous_epochs}\", end=\"\")\n",
    "                    if segment_i==0:\n",
    "                        print(f\"\\n|  Image {1+image_i}/{len(img_pathnames)} '{img_pathnames[image_i]}'\", end=\"\")\n",
    "                \n",
    "                    time_elapsed = time.process_time()-since\n",
    "\n",
    "                    # Make new prediction so compare before and after step\n",
    "                    new_prediction = model(img_seg)\n",
    "                    new_loss = criterion(new_prediction, label_seg)\n",
    "                    ori_lab_seg = label_seg.cpu().detach().numpy()[0,:,:].astype(int)\n",
    "                    pred_lab_seg = torch.argmax(prediction, dim=1).cpu().detach().numpy()[0, :, :]\n",
    "\n",
    "                    emb_surf_pred_error = compute_emb_surf_pred_error(ori_lab_seg, pred_lab_seg, print_values=False)\n",
    "                    print(f\"\\n|  |  Segment {1+segment_i}/{len(image_segments[:, 0, 0])} : loss={loss} \"+\\\n",
    "                          f\"duration={int(time_elapsed)//60}m {int(time_elapsed%60)}s {int(1000*(time_elapsed-int(time_elapsed)))}ms. Loss reduced {loss-new_loss}. \"+\\\n",
    "                          f\"Emb surf pred err= {emb_surf_pred_error}%\", end=\"\")\n",
    "                        \n",
    "                    # # Also optionally print confusion values :\n",
    "                    # print(f\"\\n|  |  Confusion values are :{confusion(ori_lab_seg, pred_lab_seg, data_type='numpy')}\")\n",
    "                    \n",
    "                    # Also optionnaly print image segment, label and prediction\n",
    "                    if print_images_while_training == True:\n",
    "                        _ , axs = plt.subplots(ncols=3, figsize=(40, 40))\n",
    "                        axs[0].set_title(\"Segment of original image\")\n",
    "                        axs[0].imshow(img_seg.cpu().detach().numpy()[0,0,:,:])\n",
    "                        axs[1].set_title(\"Segment of original label\")\n",
    "                        axs[1].imshow(label_seg.cpu().detach().numpy()[0,:,:])\n",
    "                        axs[2].set_title(\"Predicted label segment\")\n",
    "                        axs[2].imshow(torch.argmax(prediction, dim=1).cpu().detach().numpy()[0,:,:])\n",
    "                        plt.show()\n",
    "                    \n",
    "                    points=0\n",
    "\n",
    "                if ( (epoch%disp_every_x_epoch==0 and image_i%disp_every_x_img==1 and segment_i==0) \n",
    "                        or (epoch%disp_every_x_epoch==1 and points==0) ):\n",
    "                    print(\"\\n   ...Next epochs & images \", end=\"\")\n",
    "                    points = 1\n",
    "                else:\n",
    "                    print(\".\", end=\"\")\n",
    "                    points = points+1 \n",
    "                    if  points>100:\n",
    "                        print(\"\\n      ...\", end=\"\")\n",
    "                        points = 1\n",
    "                \n",
    "                segment_i = updated_segment_i + 1\n",
    "                        \n",
    "    time_elapsed = time.process_time()-train_start_time\n",
    "    print(f\"\\n\\n Finished training after {int(time_elapsed)//60}m {int(time_elapsed%60)}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxvycGsWoKDJ",
    "outputId": "01ec10c1-12b5-4b63-9e77-dea48ed70fab"
   },
   "outputs": [],
   "source": [
    "# Actually training the model\n",
    "previous_epochs = 0 # useful to track between resumes\n",
    "if train_or_load == \"train\" : \n",
    "    model = UNet().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "elif train_or_load == \"resume\":\n",
    "    # Loading the pre-trained model\n",
    "    PATH = \"/content/drive/MyDrive/savedmodels/\" + model_name + f\"AtEpoch{num_epochs+previous_epochs}.pkl\"\n",
    "    if env == \"local\" or env == \"gcp\":\n",
    "        PATH = \"./savedmodels/\" + model_name + f\"AtEpoch{num_epochs+previous_epochs}.pkl\"\n",
    "    model = UNet()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    checkpoint = torch.load(PATH)\n",
    "    print(\"Model parameters are :\")\n",
    "    print(f\"   name : {checkpoint['name']}\")\n",
    "    print(f\"   description : {checkpoint['description']}\")\n",
    "    print(f\"   Model details dump : {checkpoint['model_details_dump']}\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    for state in optimizer.state.values():\n",
    "        for k, v in state.items():\n",
    "            if isinstance(v, torch.Tensor):\n",
    "                state[k] = v.cuda()\n",
    "#     previous_epochs = checkpoint['epoch']\n",
    "    model.to(device)\n",
    "    print(\"Model successfully loaded !\")\n",
    "    \n",
    "if train_or_load == \"train\" or train_or_load == \"resume\":\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    train_model(model, train_img_pathnames, train_label_pathnames, criterion, optimizer, device, num_epochs,\n",
    "                disp_every_x_epoch,\n",
    "                disp_every_x_img,\n",
    "                max_seg_to_disp,\n",
    "                disp_every_x_seg,\n",
    "                previous_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nsFNNge0h3eZ"
   },
   "outputs": [],
   "source": [
    "# Loading the pre-trained model\n",
    "if train_or_load == \"load\":  \n",
    "    PATH = \"/content/drive/MyDrive/savedmodels/\" + model_name + f\"AtEpoch{num_epochs+previous_epochs}.pkl\"\n",
    "    if env == \"local\" or env == \"gcp\":\n",
    "        PATH = \"./savedmodels/\" + model_name + f\"AtEpoch{num_epochs+previous_epochs}.pkl\"\n",
    "\n",
    "    if device == \"cuda\":\n",
    "        map_to_device = \"cuda:0\"\n",
    "    else:\n",
    "        map_to_device = \"cpu\"\n",
    "\n",
    "    model = UNet()\n",
    "\n",
    "    checkpoint = torch.load(PATH)\n",
    "\n",
    "    print(\"Model parameters are :\")\n",
    "    print(f\"   name : {checkpoint['name']}\")\n",
    "    print(f\"   description : {checkpoint['description']}\")\n",
    "    print(f\"   Model details dump : {checkpoint['model_details_dump']}\")\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "#     # If wanting to resume training :\n",
    "#     optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "#     optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "\n",
    "    model.to(device)\n",
    "    print(\"Model successfully loaded !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "Sc0iyD5toKDJ",
    "outputId": "f656ba85-d1ab-47b6-ed43-0c2f139b3b82"
   },
   "outputs": [],
   "source": [
    "# Test predictions\n",
    "def test_predictions(model, test_img_pathnames, test_label_pathnames):\n",
    "    emb_surf_pred_errors_list = []\n",
    "\n",
    "    print(\"Starting testing predictions \\n\")\n",
    "\n",
    "    for img_i in range(len(test_img_pathnames)):\n",
    "        test_img = cv.imread(test_img_pathnames[img_i], cv.IMREAD_UNCHANGED)\n",
    "        test_label = png_to_mask(cv.imread(test_label_pathnames[img_i], cv.IMREAD_UNCHANGED))\n",
    "\n",
    "        pred_label = out_predict(model, test_img, device)\n",
    "\n",
    "        emb_surf_pred_error = compute_emb_surf_pred_error(test_label, pred_label, print_values=False)\n",
    "        if print_each_test_stat == True:\n",
    "            print(f\"Emb surf pred err={emb_surf_pred_error}%\")\n",
    "            print(f\"Confusion values are :{confusion(pred_label, test_label, data_type='numpy')}\")\n",
    "        else:\n",
    "            print(\".\", end=\"\")\n",
    "        emb_surf_pred_errors_list.append(emb_surf_pred_error)\n",
    "\n",
    "        if img_i == len(test_img_pathnames)-1 or print_each_test_img == True:\n",
    "            print(\"\\nLast image looks like :\")\n",
    "            _ , axs = plt.subplots(ncols=3, figsize=(40, 40))\n",
    "\n",
    "            axs[0].set_title(\"Original image\")\n",
    "            axs[0].imshow(test_img)\n",
    "\n",
    "            axs[1].set_title(\"Original label\")\n",
    "            axs[1].imshow(test_label)\n",
    "\n",
    "            axs[2].set_title(\"Model predicted label\")\n",
    "            axs[2].imshow(pred_label)\n",
    "            plt.show()\n",
    "\n",
    "    # Draw histogram with boxplot of surface error values\n",
    "    sns.set(style=\"ticks\")\n",
    "    f, (ax_box, ax_hist) = plt.subplots(2, sharex=True, \n",
    "                                        gridspec_kw={\"height_ratios\": (.15, .85)})\n",
    "    f.suptitle(f\"Surface error distribution for {len(test_img_pathnames)} images\")\n",
    "    sns.boxplot(x=emb_surf_pred_errors_list, ax=ax_box)\n",
    "    sns.histplot(x=emb_surf_pred_errors_list, ax=ax_hist)\n",
    "    ax_box.set(yticks=[])\n",
    "    sns.despine(ax=ax_hist)\n",
    "    sns.despine(ax=ax_box, left=True)\n",
    "    plt.show()\n",
    "    plt.style.use('default')\n",
    "\n",
    "    print(f\"Finished testing with mean surface error={np.mean(emb_surf_pred_errors_list)}%\")\n",
    "    \n",
    "test_predictions(model, test_img_pathnames, test_label_pathnames)\n",
    "\n",
    "if train_or_load == \"train\" or train_or_load == \"resume\" :\n",
    "    print(\"\\n\\nCheck of performance on training set :\")\n",
    "    test_predictions(model, train_img_pathnames, train_label_pathnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "js_Ac9KAoKDK"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "if train_or_load == \"train\" or train_or_load == \"resume\":\n",
    "    print(f\"Remember to set a model name that makes it easy to identify\")\n",
    "    print(f\"Here are the notebook parameters : \\ncriterion={criterion} \\noptimizer={optimizer} \\nlr={learning_rate}, \\nepochs={num_epochs}, \\nPrevEpoch={previous_epochs}\")\n",
    "    \n",
    "    PATH = \"/content/drive/MyDrive/savedmodels/\" + model_name + f\"AtEpoch{num_epochs+previous_epochs}.pkl\"\n",
    "    if env == \"local\" or env == \"gcp\":\n",
    "        PATH = \"./savedmodels/\" + model_name + f\"AtEpoch{num_epochs+previous_epochs}.pkl\"\n",
    "\n",
    "    print(\"\\nmodel_name = \" + model_name)\n",
    "    print(\"model_description = \" + model_description)\n",
    "    print(\"PATH = \" + PATH)\n",
    "    # Warning : only save once name and descriptions are set correctly\n",
    "    if save_for_resume == True:\n",
    "        torch.save({\n",
    "                'name': model_name,\n",
    "                'epoch': num_epochs + previous_epochs,\n",
    "                'description': model_description,\n",
    "                'model_details_dump': f\"env={env}, train_or_load={train_or_load}, learning rate={learning_rate}, epochs={num_epochs}, PrevEpoch={previous_epochs}, optimizer={optimizer}, criterion={criterion}\",         \n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(), # Only needed when planning to resume training from loaded model\n",
    "                }, PATH)\n",
    "    else:\n",
    "        torch.save({\n",
    "                'name': model_name,\n",
    "                'epoch': num_epochs + previous_epochs,\n",
    "                'description': model_description,\n",
    "                'model_details_dump': f\"env={env}, train_or_load={train_or_load}, learning rate={learning_rate}, epochs={num_epochs}, PrevEpoch={previous_epochs}, optimizer={optimizer}, criterion={criterion}\",         \n",
    "                'model_state_dict': model.state_dict(),\n",
    "                }, PATH)\n",
    "    print(\"Model saved !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "th_u_net_ref_for_tests.ipynb",
   "provenance": []
  },
  "environment": {
   "name": "common-cu110.m59",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m59"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
