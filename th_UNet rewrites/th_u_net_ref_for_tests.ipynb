{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QKbc3s9LoKC8"
   },
   "source": [
    "# Using https://youtu.be/u1loyDCoGbE for implementation of U-net : https://arxiv.org/pdf/1505.04597.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "dtCj1z1-oKDE"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_FzWBgbHoKDF",
    "outputId": "5f60d21b-d118-4a21-a9c9-a47dd1401544"
   },
   "outputs": [],
   "source": [
    "# #Google Collab specifics\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "# !cp \"/content/drive/MyDrive/helpers.py\" .\n",
    "# imgs_names = glob.glob( '/content/drive/MyDrive/th_analysedimages/*.tif')\n",
    "# labels_names = glob.glob('/content/drive/MyDrive/labels/*.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "B-sPlOI_oKDH"
   },
   "outputs": [],
   "source": [
    "#Local github project specifics\n",
    "imgs_names = glob.glob( '/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/th_analysedimages/*.tif')\n",
    "labels_names = glob.glob('/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/th_csv_labels/png_masks_emb/*.png')\n",
    "!cp \"/Users/theophanemayaud/Dev/EPFL MA1/Machine Learning/cs-433-project-2-ml_fools/helpers.py\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GIo9U3weoKDH",
    "outputId": "f0dfcefe-c285-426a-ec40-6c0f657de49d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 357 images\n",
      "Found 357 labels\n"
     ]
    }
   ],
   "source": [
    "imgs_names= sorted(imgs_names)\n",
    "#imgs = [cv.imread(name, cv.IMREAD_UNCHANGED) for name in imgs_names[1]]\n",
    "print(f\"Found {len(imgs_names)} images\")\n",
    "\n",
    "labels_names= sorted(labels_names)\n",
    "#labels = [png_to_mask(cv.imread(name, cv.IMREAD_UNCHANGED)) for name in labels_names]\n",
    "print(f\"Found {len(labels_names)} labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rK-k0p8PoKDH"
   },
   "source": [
    "<img src=\"./U-Net structure.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "fscs-r1JoKDH"
   },
   "outputs": [],
   "source": [
    "# UNet definitions\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        \n",
    "        # functions for going down the U\n",
    "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.d_double_conv_1 = double_conv(1, 64)\n",
    "        self.d_double_conv_2 = double_conv(64, 128)\n",
    "        self.d_double_conv_3 = double_conv(128, 256)\n",
    "        self.d_double_conv_4 = double_conv(256, 512)\n",
    "        self.d_double_conv_5 = double_conv(512, 1024)\n",
    "        \n",
    "        # functions for going up the U\n",
    "        self.up_trans_4 = nn.ConvTranspose2d(in_channels=1024, out_channels=512, kernel_size=2, stride=2)        \n",
    "        self.u_double_conv_4 = double_conv(1024, 512)\n",
    "        self.up_trans_3 = nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_3 = double_conv(512, 256)\n",
    "        self.up_trans_2 = nn.ConvTranspose2d(in_channels=256, out_channels=128, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_2 = double_conv(256, 128)\n",
    "        self.up_trans_1 = nn.ConvTranspose2d(in_channels=128, out_channels=64, kernel_size=2, stride=2)\n",
    "        self.u_double_conv_1 = double_conv(128, 64)\n",
    "        \n",
    "        self.out = nn.Conv2d(in_channels=64, out_channels=2, kernel_size=1)\n",
    "        # self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, image):\n",
    "        '''makes the 388x388 prediction with the model, image must be 572x572pixels'''\n",
    "        \n",
    "        # Going down the U\n",
    "        d1 = self.d_double_conv_1(image) # first \"level\"\n",
    "        # print(x1.size())\n",
    "        x = self.max_pool_2x2(d1)\n",
    "        d2 = self.d_double_conv_2(x) # second\n",
    "        x = self.max_pool_2x2(d2)\n",
    "        d3 = self.d_double_conv_3(x) # third\n",
    "        x = self.max_pool_2x2(d3)\n",
    "        d4 = self.d_double_conv_4(x) # fourth\n",
    "        x = self.max_pool_2x2(d4)\n",
    "        x = self.d_double_conv_5(x) # last layer (fifth) : no max pool\n",
    "        # plt.imshow(x.detach().numpy()[0, 0, :, :])\n",
    "        \n",
    "        # Going up the U\n",
    "        x = self.up_trans_4(x)\n",
    "        d4 = crop_img(tensor=d4, target_tensor=x) #crop to copy\n",
    "        x = self.u_double_conv_4(torch.cat([d4, x], 1))\n",
    "        \n",
    "        x = self.up_trans_3(x)\n",
    "        d3 = crop_img(tensor=d3, target_tensor=x)\n",
    "        x = self.u_double_conv_3(torch.cat([d3, x], 1))\n",
    "        \n",
    "        x = self.up_trans_2(x)\n",
    "        d2 = crop_img(tensor=d2, target_tensor=x)\n",
    "        x = self.u_double_conv_2(torch.cat([d2, x], 1))\n",
    "        \n",
    "        x = self.up_trans_1(x)\n",
    "        d1 = crop_img(tensor=d1, target_tensor=x)\n",
    "        x = self.u_double_conv_1(torch.cat([d1, x], 1))\n",
    "        \n",
    "        x = self.out(x)\n",
    "        # x = self.sigmoid(x) # see https://medium.com/analytics-vidhya/simple-neural-network-with-bceloss-for-binary-classification-for-a-custom-dataset-8d5c69ffffee why necessary\n",
    "        return x\n",
    "        \n",
    "        \n",
    "    \n",
    "# some functions so reduce redunduncy\n",
    "def double_conv(nb_in_channels, nb_out_channels):\n",
    "    conv = nn.Sequential(\n",
    "        nn.Conv2d(nb_in_channels, nb_out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.Conv2d(nb_out_channels, nb_out_channels, kernel_size=3),\n",
    "        nn.ReLU(inplace=True),\n",
    "    )\n",
    "    return conv\n",
    "\n",
    "def crop_img(tensor, target_tensor):\n",
    "    target_size = target_tensor.size()[2] # NB they are square so .size[2]=.size[3]\n",
    "    tensor_size = tensor.size()[2]\n",
    "    delta = tensor_size - target_size #target is always smaller\n",
    "    pix_crop = delta // 2\n",
    "    return tensor[:, :, pix_crop:tensor_size-pix_crop, pix_crop:tensor_size-pix_crop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "LzxmDx5doKDI"
   },
   "outputs": [],
   "source": [
    "# Test forward to see how it behaves\n",
    "# image = torch.rand((1, 1, 572, 572))\n",
    "# print(image.type())\n",
    "# model = UNet()\n",
    "# y = model(image).detach().numpy()\n",
    "# print(f\"Output shape : {y.shape}\")\n",
    "# print(f\"Output max value : {y[0,0, :, :].max()}, min={y[0,0, :, :].min()}\")\n",
    "# _ , axs = plt.subplots(ncols=2)\n",
    "# axs[0].imshow(image.detach().numpy()[0,0,:,:])\n",
    "# axs[0].set_title(\"Original image\")\n",
    "# axs[1].imshow(y[0,0, :, :])\n",
    "# axs[1].set_title(\"Output label image\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "MPu2o3zAoKDI"
   },
   "outputs": [],
   "source": [
    "# Training function\n",
    "from helpers import png_to_mask, segment_dataset\n",
    "\n",
    "def train_model(model, img_pathnames, label_pathnames, criterion, optimizer, device, num_epochs=25):\n",
    "    \n",
    "    print(\"Starting the training on images !\\n\")\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {1+epoch}/{num_epochs}\", end=\"\")\n",
    "        \n",
    "        for image_i in range(len(img_pathnames)):\n",
    "            image = cv.imread(img_pathnames[image_i], cv.IMREAD_UNCHANGED)\n",
    "            label = png_to_mask(cv.imread(label_pathnames[image_i], cv.IMREAD_UNCHANGED))\n",
    "            \n",
    "            image_segments, label_segments = segment_dataset([image], [label])\n",
    "            \n",
    "            for segment_i in range(len(image_segments[:, 0, 0])):\n",
    "                since = time.process_time() # For process monitoring\n",
    "                img_seg = torch.tensor(image_segments[segment_i, :, :], requires_grad=True).view(1, 1, 572, 572).to(device).float()\n",
    "                label_seg = torch.tensor(label_segments[segment_i, :, :].astype(float)).view(1, 388, 388).to(device).long()\n",
    "                \n",
    "                prediction = model(img_seg)\n",
    "                loss = criterion(prediction, label_seg)\n",
    "            \n",
    "                # Compute the gradient\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                \n",
    "                # Update the parameters of the model with a gradient step\n",
    "                optimizer.step()\n",
    "                            \n",
    "                disp_img_mod = 50\n",
    "                if image_i%disp_img_mod==0:\n",
    "                    time_elapsed = time.process_time()-since\n",
    "                    if segment_i==0:\n",
    "                        print(f\"\\n|  Image {1+image_i}/{len(img_pathnames)} '{img_pathnames[image_i]}'\", end=\"\")\n",
    "                    if segment_i%3==0 and segment_i<9:\n",
    "                        new_prediction = model(img_seg)\n",
    "                        new_loss = criterion(new_prediction, label_seg)\n",
    "\n",
    "                        ori_lab_seg = label_seg.cpu().detach().numpy()[0,:,:].astype(int)\n",
    "                        pred_lab_seg = torch.argmax(prediction, dim=1).cpu().detach().numpy()[0, :, :]\n",
    "                        ori_lab_counts = np.count_nonzero(ori_lab_seg == 1)\n",
    "                        pred_lab_counts = np.count_nonzero(pred_lab_seg == 1)\n",
    "                        # if image_i%100==0:\n",
    "                        #     print(\"Error of 0 label pixels in original label...\")\n",
    "                        #     _ , axs = plt.subplots(ncols=3, figsize=(40, 40))\n",
    "                        #     axs[0].set_title(\"Segment of original image\")\n",
    "                        #     axs[0].imshow(img_seg.cpu().detach().numpy()[0,0,:,:])\n",
    "                        #     axs[1].set_title(\"Segment of original label\")\n",
    "                        #     axs[1].imshow(label_seg.cpu().detach().numpy()[0,:,:])\n",
    "                        #     axs[2].set_title(\"Predicted label segment\")\n",
    "                        #     axs[2].imshow(torch.argmax(prediction, dim=1).cpu().detach().numpy()[0,:,:])\n",
    "                        #     plt.show()\n",
    "                        if ori_lab_counts == 0:\n",
    "                            ori_lab_counts = 1; #fix when some masks are 0 to not have divide by 0\n",
    "                        emb_surf_pred_error = round(100*(pred_lab_counts-ori_lab_counts)/ori_lab_counts,4)\n",
    "                        print(f\"\\n|  |  Segment {1+segment_i}/{len(image_segments[:, 0, 0])} of image {1+image_i} : loss={loss} duration={int(time_elapsed)//60}m {int(time_elapsed%60)}s. Loss reduced {loss-new_loss}. Emb surf pred err (pred1s-orig1s)/orig1s = {emb_surf_pred_error}% (target is 0%)\", end=\"\")\n",
    "                else:\n",
    "                    if image_i%disp_img_mod==1 and segment_i==0:\n",
    "                        print(\"\\n|  Next images & segments \", end=\"\")\n",
    "                    if segment_i%6==0:\n",
    "                        print(\".\", end=\"\")\n",
    "\n",
    "    print(\"\\n Finished training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hxvycGsWoKDJ",
    "outputId": "2e097526-f42a-42ca-f7eb-c1215b699e5d"
   },
   "outputs": [],
   "source": [
    "# If a GPU is available (ex when on Google Colab)\n",
    "if not torch.cuda.is_available():\n",
    "    print(\"Things will go much quicker if you enable a GPU, ex in Colab under 'Runtime / Change Runtime Type'\")\n",
    "else:\n",
    "    del model # only needed when re-running multiple times\n",
    "    torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"    Selected device is: {device}/n\")\n",
    "    \n",
    "learning_rate = 10e-5\n",
    "model = UNet().to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "train_model(model, imgs_names, labels_names, criterion, optimizer, device, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sc0iyD5toKDJ"
   },
   "outputs": [],
   "source": [
    "# Test prediction\n",
    "img_nb = 100\n",
    "test_seg_i = 0\n",
    "test_img = cv.imread(imgs_names[img_nb], cv.IMREAD_UNCHANGED) \n",
    "test_label = png_to_mask(cv.imread(labels_names[img_nb], cv.IMREAD_UNCHANGED))\n",
    "test_image_segments, test_label_segments = segment_dataset([test_img], [test_label])\n",
    "test_img_seg = torch.tensor(test_image_segments[test_seg_i, :, :], requires_grad=True).view(1, 1, 572, 572).to(device).float()\n",
    "test_label_seg = torch.tensor(test_label_segments[test_seg_i, :, :].astype(float)).view(1, 1, 388, 388).to(device).float()\n",
    "\n",
    "model.eval()\n",
    "test_pred = model(test_img_seg)\n",
    "y_test = torch.argmax(test_pred, dim=1).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "372NYm9PoKDJ",
    "outputId": "681ee75c-804f-4f86-8eae-7ca3cbb54eec"
   },
   "outputs": [],
   "source": [
    "# Show predictions\n",
    "# y_test[y_test<0.5] = 0\n",
    "# y_test[y_test>=0.5] = 1\n",
    "y_test_round = y_test.copy()\n",
    "# y_test_round[y_test<0.5] = 0\n",
    "# y_test_round[y_test>=0.5] = 1\n",
    "\n",
    "print(f\"Output shape : {y_test_round.shape}\")\n",
    "print(f\"Output max value : {y_test_round[0, :, :].max()}, min={y_test_round[0, :, :].min()}\")\n",
    "print(f\"Output average={y_test_round.mean()}\")\n",
    "\n",
    "_ , axs = plt.subplots(ncols=3, figsize=(40, 40))\n",
    "\n",
    "axs[0].set_title(\"Original image\")\n",
    "orig_image = test_img_seg.cpu().detach().numpy()[0,0,:,:]\n",
    "axs[0].imshow(orig_image)\n",
    "\n",
    "axs[1].set_title(\"Original label\")\n",
    "ori_lab = test_label_seg.cpu().detach().numpy()[0,0,:,:]\n",
    "axs[1].imshow(ori_lab)\n",
    "\n",
    "axs[2].set_title(\"Model predicted label\")\n",
    "pred_lab = y_test_round[0, :, :]\n",
    "axs[2].imshow(pred_lab)\n",
    "\n",
    "ori_lab_seg = ori_lab.astype(int)\n",
    "pred_lab_seg = pred_lab\n",
    "ori_lab_counts = np.count_nonzero(ori_lab_seg == 1)\n",
    "pred_lab_counts = np.count_nonzero(pred_lab_seg == 1)\n",
    "print(f\"Original embolism pixels = {ori_lab_counts}, predicted={pred_lab_counts}\")\n",
    "print(f\"Emb surf pred err (orig1s-pred1s)/orig1s = {100*(ori_lab_counts-pred_lab_counts)/ori_lab_counts}% (target is 0%)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "js_Ac9KAoKDK"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "th_u_net_using_video_crossentropy_fullrun.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
